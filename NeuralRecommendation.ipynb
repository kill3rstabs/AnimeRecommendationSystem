{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "    Loading the Dataset:\n",
        "        We start by loading a dataset containing information about video games. This dataset is stored in a CSV file named 'Cleaned_games.csv'.\n",
        "\n",
        "    Processing Tags:\n",
        "        Each game in the dataset has associated tags, describing its genre, features, etc.\n",
        "        We convert the string representation of these tags into a list of strings using the ast.literal_eval function.\n",
        "        Then, we perform one-hot encoding on these tags. One-hot encoding is a way to represent categorical data (like tags) as binary vectors, where each element indicates the presence or absence of a tag.\n",
        "        Finally, we group the one-hot encoded tags by game to create a DataFrame where each row represents a game and each column represents a tag.\n",
        "\n",
        "    Normalizing Numerical Features:\n",
        "        We scale the 'positive_ratio' column, which represents the percentage of positive reviews for each game, using Min-Max scaling. This ensures that all numerical features are on a similar scale, which is important for training the neural network.\n",
        "\n",
        "    Neural Network Architecture:\n",
        "        We define a neural network architecture using Keras, a high-level deep learning library.\n",
        "        The neural network consists of multiple layers:\n",
        "            Input layer with 256 neurons (units), using ReLU activation function.\n",
        "            Dropout layer with a dropout rate of 0.5, which helps prevent overfitting by randomly dropping some neurons during training.\n",
        "            Hidden layers with 128 and 64 neurons respectively, also using ReLU activation function.\n",
        "            Output layer with 1 neuron, using linear activation function. This neuron predicts the scaled rating (positive_ratio) for each game.\n",
        "        We compile the model, specifying the loss function (mean squared error), optimizer (Adam), and evaluation metric (mean absolute error).\n",
        "\n",
        "    Training the Model:\n",
        "        We split the dataset into training and testing sets using the train_test_split function from scikit-learn.\n",
        "        Then, we train the neural network on the training data for 20 epochs (iterations), with a batch size of 128. During training, the model learns to predict the positive_ratio based on the one-hot encoded tags.\n",
        "\n",
        "    Saving Model Weights:\n",
        "        Once the model is trained, we save its weights to a file named 'model_weights.h5'. These weights represent the learned parameters of the neural network.\n",
        "\n",
        "    Predicting Positive Ratio:\n",
        "        We define a function called predict_positive_ratio to predict the positive_ratio for a given set of input tags.\n",
        "        The input tags are preprocessed to match the format used during training (one-hot encoding).\n",
        "        Using the trained model and the preprocessed input tags, we make a prediction for the positive_ratio.\n",
        "        Finally, we print out the predicted positive_ratio.\n",
        "\n",
        "Overall, this code demonstrates how to train a neural network to predict the positive_ratio of video games based on their associated tags, and how to use the trained model to make predictions for new sets of tags."
      ],
      "metadata": {
        "id": "CsDBiXqbCDEE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import ast\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "\n",
        "# Load dataset\n",
        "data = pd.read_csv('Cleaned_games.csv')\n",
        "\n",
        "# Convert string representation of tags to list of strings\n",
        "tags_list = data['tags'].apply(ast.literal_eval)\n",
        "\n",
        "# One-hot encode tags\n",
        "tags = pd.get_dummies(tags_list.apply(pd.Series).stack()).groupby(level=0).sum()\n",
        "\n",
        "# Reset index of tags\n",
        "tags.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Filter out rows with no tags\n",
        "data_with_tags = data.iloc[tags.index]\n",
        "\n",
        "# Normalize numerical features\n",
        "scaler = MinMaxScaler()\n",
        "data_with_tags['rating_scaled'] = scaler.fit_transform(data_with_tags['positive_ratio'].values.reshape(-1, 1))\n",
        "\n",
        "# Combine features\n",
        "X = tags  # Features are just the one-hot encoded tags for rows with tags\n",
        "y = data_with_tags['rating_scaled'].values  # Target variable is the scaled rating\n",
        "\n",
        "# Split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Neural Network Architecture\n",
        "model = Sequential()\n",
        "model.add(Dense(256, activation='relu', input_shape=(X_train.shape[1],)))\n",
        "model.add(Dropout(0.5))  # Dropout layer to prevent overfitting\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(1, activation='linear'))  # Output layer predicts the scaled rating\n",
        "\n",
        "# Compile model\n",
        "model.compile(loss='mse', optimizer='adam', metrics=['mae'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train, epochs=20, batch_size=128, validation_split=0.2)\n",
        "\n",
        "# Save weights\n",
        "model.save_weights('model_weights.h5')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VgQiLboUk8mL",
        "outputId": "a083edeb-4731-4bb8-fdf9-6dc67d692280"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-d82fcf9d461e>:26: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data_with_tags['rating_scaled'] = scaler.fit_transform(data_with_tags['positive_ratio'].values.reshape(-1, 1))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "249/249 [==============================] - 3s 9ms/step - loss: 0.0664 - mae: 0.1989 - val_loss: 0.0494 - val_mae: 0.1933\n",
            "Epoch 2/20\n",
            "249/249 [==============================] - 2s 8ms/step - loss: 0.0365 - mae: 0.1521 - val_loss: 0.0367 - val_mae: 0.1608\n",
            "Epoch 3/20\n",
            "249/249 [==============================] - 2s 9ms/step - loss: 0.0337 - mae: 0.1458 - val_loss: 0.0338 - val_mae: 0.1504\n",
            "Epoch 4/20\n",
            "249/249 [==============================] - 2s 8ms/step - loss: 0.0331 - mae: 0.1442 - val_loss: 0.0331 - val_mae: 0.1459\n",
            "Epoch 5/20\n",
            "249/249 [==============================] - 3s 11ms/step - loss: 0.0326 - mae: 0.1429 - val_loss: 0.0338 - val_mae: 0.1496\n",
            "Epoch 6/20\n",
            "249/249 [==============================] - 2s 9ms/step - loss: 0.0324 - mae: 0.1425 - val_loss: 0.0347 - val_mae: 0.1541\n",
            "Epoch 7/20\n",
            "249/249 [==============================] - 2s 8ms/step - loss: 0.0320 - mae: 0.1413 - val_loss: 0.0334 - val_mae: 0.1465\n",
            "Epoch 8/20\n",
            "249/249 [==============================] - 2s 8ms/step - loss: 0.0315 - mae: 0.1398 - val_loss: 0.0347 - val_mae: 0.1538\n",
            "Epoch 9/20\n",
            "249/249 [==============================] - 2s 8ms/step - loss: 0.0309 - mae: 0.1386 - val_loss: 0.0343 - val_mae: 0.1512\n",
            "Epoch 10/20\n",
            "249/249 [==============================] - 2s 9ms/step - loss: 0.0304 - mae: 0.1372 - val_loss: 0.0352 - val_mae: 0.1551\n",
            "Epoch 11/20\n",
            "249/249 [==============================] - 3s 13ms/step - loss: 0.0295 - mae: 0.1352 - val_loss: 0.0353 - val_mae: 0.1552\n",
            "Epoch 12/20\n",
            "249/249 [==============================] - 2s 8ms/step - loss: 0.0289 - mae: 0.1336 - val_loss: 0.0346 - val_mae: 0.1522\n",
            "Epoch 13/20\n",
            "249/249 [==============================] - 2s 8ms/step - loss: 0.0281 - mae: 0.1312 - val_loss: 0.0349 - val_mae: 0.1517\n",
            "Epoch 14/20\n",
            "249/249 [==============================] - 2s 8ms/step - loss: 0.0271 - mae: 0.1283 - val_loss: 0.0369 - val_mae: 0.1588\n",
            "Epoch 15/20\n",
            "249/249 [==============================] - 2s 9ms/step - loss: 0.0267 - mae: 0.1277 - val_loss: 0.0359 - val_mae: 0.1530\n",
            "Epoch 16/20\n",
            "249/249 [==============================] - 2s 8ms/step - loss: 0.0259 - mae: 0.1253 - val_loss: 0.0375 - val_mae: 0.1588\n",
            "Epoch 17/20\n",
            "249/249 [==============================] - 3s 12ms/step - loss: 0.0254 - mae: 0.1239 - val_loss: 0.0371 - val_mae: 0.1570\n",
            "Epoch 18/20\n",
            "249/249 [==============================] - 2s 8ms/step - loss: 0.0246 - mae: 0.1217 - val_loss: 0.0367 - val_mae: 0.1550\n",
            "Epoch 19/20\n",
            "249/249 [==============================] - 2s 8ms/step - loss: 0.0242 - mae: 0.1210 - val_loss: 0.0365 - val_mae: 0.1548\n",
            "Epoch 20/20\n",
            "249/249 [==============================] - 2s 7ms/step - loss: 0.0239 - mae: 0.1197 - val_loss: 0.0372 - val_mae: 0.1567\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to predict positive_ratio based on input tags array\n",
        "def predict_positive_ratio(input_tags):\n",
        "    # Preprocess input tags array to match the format used for training\n",
        "    input_tags_df = pd.DataFrame(np.zeros((1, tags.shape[1])), columns=tags.columns)\n",
        "    for tag in input_tags:\n",
        "        if tag in input_tags_df.columns:\n",
        "            input_tags_df[tag] = 1\n",
        "    # Make prediction\n",
        "    prediction = model.predict(input_tags_df)\n",
        "    return (prediction[0][0] * 100)\n",
        "\n",
        "# Example input tags array\n",
        "input_tags = ['Action', 'Adventure', 'Open World', 'RPG', 'Singleplayer']\n",
        "\n",
        "# Predict positive_ratio based on input tags array\n",
        "predicted_positive_ratio = predict_positive_ratio(input_tags)\n",
        "print(\"Predicted Positive Ratio:\", predicted_positive_ratio)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GtFMDgpBszNF",
        "outputId": "e6ff2c1f-6bef-4ddf-9774-d6bcc30be476"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 26ms/step\n",
            "Predicted Positive Ratio: 80.9302270412445\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Mnvu-LJqAkye"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}